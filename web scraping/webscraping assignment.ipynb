{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19fbe9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\s\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f54da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52da1788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header\n",
       "0                      Main Page\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1)#Write a python program to display all the header tags from wikipedia.org and make data frame\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "import pandas as pd\n",
    "htags =[]\n",
    "for i in Soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    htags.append(i.text)\n",
    "htags\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Header':htags})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae4f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>36</td>\n",
       "      <td>4,081</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>28</td>\n",
       "      <td>2,661</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>16</td>\n",
       "      <td>1,404</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>32</td>\n",
       "      <td>2,794</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name matches points rating\n",
       "0     Australia      23  2,714    116\n",
       "1      Pakistan      20  2,316    113\n",
       "2         India      36  4,081    104\n",
       "3   New Zealand      27  2,806    101\n",
       "4       England      24  2,426    101\n",
       "5  South Africa      19  1,910     95\n",
       "6    Bangladesh      28  2,661     88\n",
       "7   Afghanistan      16  1,404     87\n",
       "8     Sri Lanka      32  2,794     68\n",
       "9   West Indies      38  2,582     55"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3)#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "#c) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "#3)A) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "import pandas as pd\n",
    "name=[]\n",
    "for i in Soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    name.append(i.text) \n",
    "point=[]\n",
    "for i in Soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    point.append(i.text) \n",
    "match=[]\n",
    "for i in Soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    match.append(i.text)\n",
    "rating=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "n=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    n.append(i.text)\n",
    "for i in range(0,len(n)-1,2):\n",
    "    match.append(n[i]) \n",
    "    point.append(n[i+1]) \n",
    "for i in Soup.find_all(\"td\",class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text)\n",
    "df1=pd.DataFrame({})\n",
    "df1['name']=pd.Series(name[:10])\n",
    "df1['matches']=pd.Series(match[:10])\n",
    "df1['points']=pd.Series(point[:10])\n",
    "df1['rating']=pd.Series(rating[:10])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d22d14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Batsman Team Rating\n",
       "0  Rassie van der Dussen   SA    777\n",
       "1           Fakhar Zaman  PAK    755\n",
       "2            Imam-ul-Haq  PAK    745\n",
       "3           Shubman Gill  IND    743\n",
       "4           Harry Tector  IRE    726\n",
       "5           David Warner  AUS    726\n",
       "6        Quinton de Kock   SA    718\n",
       "7            Virat Kohli  IND    705\n",
       "8            Steve Smith  AUS    702\n",
       "9           Rohit Sharma  IND    693"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "Menplayer=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Menplayer.append(i.text.strip())\n",
    "Menplayer[:10]\n",
    "teams1=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    teams1.append(i.text.strip())\n",
    "teams1[:10]\n",
    "ra=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    ra.append(i.text)\n",
    "ra[:10]\n",
    "import pandas as pd\n",
    "df2=pd.DataFrame({'Batsman':Menplayer,'Team':teams1,'Rating':ra})\n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf47c9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bowler Team Rating\n",
       "0    Mitchell Starc  AUS    686\n",
       "1       Rashid Khan  AFG    682\n",
       "2    Mohammed Siraj  IND    670\n",
       "3        Matt Henry   NZ    667\n",
       "4  Mujeeb Ur Rahman  AFG    661\n",
       "5       Trent Boult   NZ    660\n",
       "6        Adam Zampa  AUS    652\n",
       "7    Shaheen Afridi  PAK    630\n",
       "8     Kuldeep Yadav  IND    622\n",
       "9   Shakib Al Hasan  BAN    618"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3c) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "Menplayer=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Menplayer.append(i.text.strip())\n",
    "Menplayer[:10]\n",
    "teams2=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    teams2.append(i.text.strip())\n",
    "teams2[:10]\n",
    "ra1=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    ra1.append(i.text)\n",
    "ra1[:10]\n",
    "import pandas as pd\n",
    "df3=pd.DataFrame({'Bowler':Menplayer,'Team':teams2,'Rating':ra1})\n",
    "df3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aeabf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>31</td>\n",
       "      <td>3,875</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,039</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1,284</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name matches points rating\n",
       "0     Australia      26  4,290    125\n",
       "1       England      31  3,875    119\n",
       "2  South Africa      26  3,098    101\n",
       "3         India      30  3,039     96\n",
       "4   New Zealand      28  2,688     95\n",
       "5   West Indies      29  2,743     76\n",
       "6    Bangladesh      17  1,284     68\n",
       "7     Sri Lanka      12    820     68\n",
       "8      Thailand      13    883     62\n",
       "9      Pakistan      27  1,678     37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "4#A)Top 10 ODI teamsin women’s cricket along with the records for matches, points and rating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "import pandas as pd\n",
    "name=[]\n",
    "for i in Soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    name.append(i.text) \n",
    "point=[]\n",
    "for i in Soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    point.append(i.text) \n",
    "match=[]\n",
    "for i in Soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    match.append(i.text)\n",
    "rating=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "n=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    n.append(i.text)\n",
    "for i in range(0,len(n)-1,2):\n",
    "    match.append(n[i]) \n",
    "    point.append(n[i+1]) \n",
    "for i in Soup.find_all(\"td\",class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text)\n",
    "df = pd.DataFrame({})\n",
    "df['name']=pd.Series(name[:10])\n",
    "df['matches']=pd.Series(match[:10])\n",
    "df['points']=pd.Series(point[:10])\n",
    "df['rating']=pd.Series(rating[:10])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19492590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batswomen</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Batswomen Team Rating\n",
       "0  Chamari Athapaththu   SL    758\n",
       "1          Beth Mooney  AUS    751\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3      Smriti Mandhana  IND    708\n",
       "4         Alyssa Healy  AUS    702\n",
       "5     Harmanpreet Kaur  IND    694\n",
       "6         Ellyse Perry  AUS    686\n",
       "7          Meg Lanning  AUS    682\n",
       "8      Stafanie Taylor   WI    618\n",
       "9       Tammy Beaumont  ENG    616"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4) b) Top 10 women’s ODI Batting players along with the records of their team and rating\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "womenplayer=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    womenplayer.append(i.text.strip())\n",
    "womenplayer[:10]\n",
    "teams=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    teams.append(i.text.strip())\n",
    "teams[:10]\n",
    "ra=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    ra.append(i.text)\n",
    "ra[:10]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Batswomen':womenplayer,'Team':teams,'Rating':ra})\n",
    "df[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4df7f9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALROUNDERWOMEN</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALROUNDERWOMEN Team Rating\n",
       "0   Ashleigh Gardner  AUS    389\n",
       "1    Hayley Matthews   WI    382\n",
       "2     Marizanne Kapp   SA    349\n",
       "3       Ellyse Perry  AUS    329\n",
       "4        Amelia Kerr   NZ    328\n",
       "5      Deepti Sharma  IND    312\n",
       "6      Jess Jonassen  AUS    241\n",
       "7      Sophie Devine   NZ    233\n",
       "8           Nida Dar  PAK    232\n",
       "9  Sophie Ecclestone  ENG    200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "womenplayer=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    womenplayer.append(i.text.strip())\n",
    "womenplayer[:10]\n",
    "teams=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    teams.append(i.text.strip())\n",
    "teams[:10]\n",
    "ra=[]\n",
    "for i in Soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    ra.append(i.text)\n",
    "ra[:10]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'ALROUNDERWOMEN':womenplayer,'Team':teams,'Rating':ra})\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "388b1409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadLine</th>\n",
       "      <th>Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why 'career choices' is the No. 1 conflict amo...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cruise will reduce robotaxi fleet by 50% in Sa...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can American-made weapons like F-16s turn the ...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harvard gut doctor avoids these 4 foods that c...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The clash of sustainability and AI is creating...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On tap next week: 2 housing reports and 2 Inve...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Top 10 best European cities for retirement</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google's plan to purge inactive accounts isn't...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The No. 1 best state to retire in the U.S.—it'...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mark Cuban passed on an Uber investment that c...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Believing these 5 Social Security myths may re...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here's why Aldi is looking to the Southern U.S...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Here's how the Huy Fong Foods sriracha shortag...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This ETF is soaring in August as market swoon ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Morgan Stanley is among the most oversold in t...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Buy these stocks with upside as market fears i...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Palo Alto shares rise on earnings beat, after ...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wall Street awaits hotly anticipated Nvidia ea...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WeWork plunges another 11% after announcing re...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The iPhone 15 could get one of the biggest upg...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Coral bleaching event in Florida is 'just the ...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bitcoin is giving a bearish signal. Here’s wha...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Earnings show shoppers will spend money for va...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nvidia, key Powell speech to take center stage...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>My HomePod is now a very expensive doorstop</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3 trends are dividing restaurant companies int...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How hurricanes may affect the 2024 Social Secu...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rosenblatt names its top picks to play the ‘ag...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>It may be tough for Apple to outperform from h...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'Blue Beetle' tries to take down 'Barbie' in a...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/barbie-vs-blue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             HeadLine             Time  \\\n",
       "0   Why 'career choices' is the No. 1 conflict amo...     12 Hours Ago   \n",
       "1   Cruise will reduce robotaxi fleet by 50% in Sa...     13 Hours Ago   \n",
       "2   Can American-made weapons like F-16s turn the ...     14 Hours Ago   \n",
       "3   Harvard gut doctor avoids these 4 foods that c...     16 Hours Ago   \n",
       "4   The clash of sustainability and AI is creating...     16 Hours Ago   \n",
       "5   On tap next week: 2 housing reports and 2 Inve...     16 Hours Ago   \n",
       "6         Top 10 best European cities for retirement      16 Hours Ago   \n",
       "7   Google's plan to purge inactive accounts isn't...     17 Hours Ago   \n",
       "8   The No. 1 best state to retire in the U.S.—it'...     17 Hours Ago   \n",
       "9   Mark Cuban passed on an Uber investment that c...     17 Hours Ago   \n",
       "10  Believing these 5 Social Security myths may re...     17 Hours Ago   \n",
       "11  Here's why Aldi is looking to the Southern U.S...     18 Hours Ago   \n",
       "12  Here's how the Huy Fong Foods sriracha shortag...     18 Hours Ago   \n",
       "13  This ETF is soaring in August as market swoon ...     18 Hours Ago   \n",
       "14  Morgan Stanley is among the most oversold in t...     18 Hours Ago   \n",
       "15  Buy these stocks with upside as market fears i...     18 Hours Ago   \n",
       "16  Palo Alto shares rise on earnings beat, after ...  August 18, 2023   \n",
       "17  Wall Street awaits hotly anticipated Nvidia ea...  August 18, 2023   \n",
       "18  WeWork plunges another 11% after announcing re...  August 18, 2023   \n",
       "19  The iPhone 15 could get one of the biggest upg...  August 18, 2023   \n",
       "20  Coral bleaching event in Florida is 'just the ...  August 18, 2023   \n",
       "21  Bitcoin is giving a bearish signal. Here’s wha...  August 18, 2023   \n",
       "22  Earnings show shoppers will spend money for va...  August 18, 2023   \n",
       "23  Nvidia, key Powell speech to take center stage...  August 18, 2023   \n",
       "24        My HomePod is now a very expensive doorstop  August 18, 2023   \n",
       "25  3 trends are dividing restaurant companies int...  August 18, 2023   \n",
       "26  How hurricanes may affect the 2024 Social Secu...  August 18, 2023   \n",
       "27  Rosenblatt names its top picks to play the ‘ag...  August 18, 2023   \n",
       "28  It may be tough for Apple to outperform from h...  August 18, 2023   \n",
       "29  'Blue Beetle' tries to take down 'Barbie' in a...  August 18, 2023   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "1   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "2   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "3   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "4   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "5   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "6   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "7   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "8   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "9   https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "10  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "11  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "12  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "13  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "14  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "15  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "16  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "17  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "18  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "19  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "20  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "21  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "22  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "23  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "24  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "25  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "26  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "27  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "28  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  \n",
       "29  https://www.cnbc.com/2023/08/18/barbie-vs-blue...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame-\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "#iii) News Link\n",
    "page = requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "#headline\n",
    "headline =[]\n",
    "for i in Soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "headline\n",
    "#time\n",
    "time=[]\n",
    "for i in Soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "#link\n",
    "for i in Soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    i=i.get('href')\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'HeadLine':headline,'Time':time,'Link':i})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f1c4796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>Authors</th>\n",
       "      <th>PublishedDate</th>\n",
       "      <th>paperUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           PaperTitle  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors   PublishedDate  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                             paperUrl  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "#https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "page = requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "papertitle=[]\n",
    "for i in Soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    papertitle.append(i.text)\n",
    "papertitle\n",
    "author=[]\n",
    "for i in Soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    author.append(i.text)\n",
    "author\n",
    "date=[]\n",
    "for i in Soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text)\n",
    "date\n",
    "for i in Soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    i=i.get('href')\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'PaperTitle':papertitle,'Authors':author,'PublishedDate':date,'paperUrl':i})\n",
    "df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbecf703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle's BarbequePacific Mall,Tagore Garden, W...</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park,Sector 51...</td>\n",
       "      <td>North Indian, Continental, Chinese, South Indian</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant Name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "2  Castle's BarbequePacific Mall,Tagore Garden, W...   \n",
       "3    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "6  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "7  The Barbeque TimesM2K Corporate Park,Sector 51...   \n",
       "8  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "0                              Chinese, North Indian   \n",
       "1                               Italian, Continental   \n",
       "2                              Chinese, North Indian   \n",
       "3                              North Indian, Italian   \n",
       "4                              North Indian, Chinese   \n",
       "5                                       North Indian   \n",
       "6                                       North Indian   \n",
       "7   North Indian, Continental, Chinese, South Indian   \n",
       "8                              North Indian, Mughlai   \n",
       "\n",
       "                                            Location Rating  \\\n",
       "0                     Connaught Place, Central Delhi      4   \n",
       "1  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "3               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida    3.9   \n",
       "5     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "6  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "7              M2K Corporate Park,Sector 51, Gurgaon    4.1   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "\n",
       "                                           Image_url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7)Write a python program to scrape mentioned details from dineout.co.in and make data frame\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "Soup =BeautifulSoup(page.content)\n",
    "Soup\n",
    "restname =[]\n",
    "for i in Soup.find_all('div',class_ =\"restnt-info cursor\"):\n",
    "    restname.append(i.text)\n",
    "restname\n",
    "cuisine =[]\n",
    "for i in Soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "cuisine\n",
    "location=[]\n",
    "for i in Soup.find_all('div',class_='restnt-loc ellipsis'):\n",
    "    location.append(i.text)\n",
    "location\n",
    "img=[]\n",
    "for i in Soup.find_all('img',\"no-img\"):\n",
    "    img.append(i['data-src'])\n",
    "img\n",
    "rating =[]\n",
    "for i in Soup.find_all('div',class_='restnt-rating rating-4'):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Restaurant Name':restname,'Cuisine':cuisine,'Location':location,\"Rating\":rating,\"Image_url\": img})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7c487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d607e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3eea48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093def6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33114b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c3be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb12c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3666cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63b8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5867c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a13d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82066b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9433a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c86be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65239107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7a10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd649c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59164cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca992d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a37bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65312b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb848d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ac3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c49c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dd00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c47132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c8fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bbe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
